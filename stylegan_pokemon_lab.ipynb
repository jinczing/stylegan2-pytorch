{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using C:\\Users\\James\\AppData\\Local\\Temp\\torch_extensions as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file C:\\Users\\James\\AppData\\Local\\Temp\\torch_extensions\\fused\\build.ninja...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\james\\stylegan2\\lib\\site-packages\\torch\\utils\\cpp_extension.py:190: UserWarning: Error checking compiler version for cl: 'utf-8' codec can't decode byte 0xb5 in position 107: invalid start byte\n",
      "  warnings.warn('Error checking compiler version for {}: {}'.format(compiler, error))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building extension module fused...\n",
      "Loading extension module fused...\n",
      "Using C:\\Users\\James\\AppData\\Local\\Temp\\torch_extensions as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file C:\\Users\\James\\AppData\\Local\\Temp\\torch_extensions\\upfirdn2d\\build.ninja...\n",
      "Building extension module upfirdn2d...\n",
      "Loading extension module upfirdn2d...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "from model import Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0995]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "discriminator = Discriminator(256, channel_multiplier=2).to(device)\n",
    "pretrained = torch.load('stylegan2-horse-config-f.pt', map_location=lambda storage, loc: storage)\n",
    "discriminator.load_state_dict(pretrained['d'])\n",
    "d_reg_ratio = (16/17)\n",
    "d_optim = torch.optim.Adam(\n",
    "        discriminator.parameters(),\n",
    "        lr=0.002 * d_reg_ratio,\n",
    "        betas=(0 ** d_reg_ratio, 0.99 ** d_reg_ratio),\n",
    "    )\n",
    "for p in discriminator.parameters():\n",
    "    p.requires_grad = True\n",
    "t = torch.randn((1, 3, 256, 256)).to(device)\n",
    "loss = discriminator(t)\n",
    "print(loss)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('stylegan2-horse-config-f.pt', map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using C:\\Users\\James\\AppData\\Local\\Temp\\torch_extensions as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file C:\\Users\\James\\AppData\\Local\\Temp\\torch_extensions\\fused\\build.ninja...\n",
      "Building extension module fused...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\james\\stylegan2\\lib\\site-packages\\torch\\utils\\cpp_extension.py:190: UserWarning: Error checking compiler version for cl: 'utf-8' codec can't decode byte 0xb5 in position 107: invalid start byte\n",
      "  warnings.warn('Error checking compiler version for {}: {}'.format(compiler, error))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error building extension 'fused'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\james\\stylegan2\\lib\\site-packages\\torch\\utils\\cpp_extension.py\u001b[0m in \u001b[0;36m_build_extension_module\u001b[1;34m(name, build_directory, verbose)\u001b[0m\n\u001b[0;32m   1029\u001b[0m                 \u001b[0mcwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuild_directory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m                 check=True)\n\u001b[0m\u001b[0;32m   1031\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\james\\anaconda3\\envs\\py36\\lib\\subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    437\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[1;32m--> 438\u001b[1;33m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[0;32m    439\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['ninja', '-v']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-dc7a4730d32e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mwandb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultiResolutionDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m from distributed import (\n",
      "\u001b[1;32m~\\projects\\stylegan2-pytorch-master\\model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFusedLeakyReLU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfused_leaky_relu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupfirdn2d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\projects\\stylegan2-pytorch-master\\op\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfused_act\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFusedLeakyReLU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfused_leaky_relu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mupfirdn2d\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mupfirdn2d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\projects\\stylegan2-pytorch-master\\op\\fused_act.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     ],\n\u001b[0;32m     17\u001b[0m     \u001b[0mextra_ldflags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'c10_cuda.lib'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\james\\stylegan2\\lib\\site-packages\\torch\\utils\\cpp_extension.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module)\u001b[0m\n\u001b[0;32m    659\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m         \u001b[0mwith_cuda\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m         is_python_module)\n\u001b[0m\u001b[0;32m    662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\james\\stylegan2\\lib\\site-packages\\torch\\utils\\cpp_extension.py\u001b[0m in \u001b[0;36m_jit_compile\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module)\u001b[0m\n\u001b[0;32m    828\u001b[0m                     \u001b[0mbuild_directory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuild_directory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 830\u001b[1;33m                     with_cuda=with_cuda)\n\u001b[0m\u001b[0;32m    831\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[0mbaton\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\james\\stylegan2\\lib\\site-packages\\torch\\utils\\cpp_extension.py\u001b[0m in \u001b[0;36m_write_ninja_file_and_build\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda)\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Building extension module {}...'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m     \u001b[0m_build_extension_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\james\\stylegan2\\lib\\site-packages\\torch\\utils\\cpp_extension.py\u001b[0m in \u001b[0;36m_build_extension_module\u001b[1;34m(name, build_directory, verbose)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'output'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\": {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'UTF-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error building extension 'fused'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, autograd, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "import torch.distributed as dist\n",
    "from torchvision import transforms, utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "\n",
    "except ImportError:\n",
    "    wandb = None\n",
    "\n",
    "from model import Generator, Discriminator\n",
    "from dataset import MultiResolutionDataset\n",
    "from distributed import (\n",
    "    get_rank,\n",
    "    synchronize,\n",
    "    reduce_loss_dict,\n",
    "    reduce_sum,\n",
    "    get_world_size,\n",
    ")\n",
    "from non_leaking import augment\n",
    "\n",
    "\n",
    "def data_sampler(dataset, shuffle, distributed):\n",
    "    if distributed:\n",
    "        return data.distributed.DistributedSampler(dataset, shuffle=shuffle)\n",
    "\n",
    "    if shuffle:\n",
    "        return data.RandomSampler(dataset)\n",
    "\n",
    "    else:\n",
    "        return data.SequentialSampler(dataset)\n",
    "\n",
    "\n",
    "def requires_grad(model, flag=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "\n",
    "def accumulate(model1, model2, decay=0.999):\n",
    "    par1 = dict(model1.named_parameters())\n",
    "    par2 = dict(model2.named_parameters())\n",
    "\n",
    "    for k in par1.keys():\n",
    "        par1[k].data.mul_(decay).add_(par2[k].data, alpha=1 - decay)\n",
    "\n",
    "\n",
    "def sample_data(loader):\n",
    "    while True:\n",
    "        for batch in loader:\n",
    "            yield batch\n",
    "\n",
    "\n",
    "def d_logistic_loss(real_pred, fake_pred):\n",
    "    real_loss = F.softplus(-real_pred)\n",
    "    fake_loss = F.softplus(fake_pred)\n",
    "\n",
    "    return real_loss.mean() + fake_loss.mean()\n",
    "\n",
    "\n",
    "def d_r1_loss(real_pred, real_img):\n",
    "    grad_real, = autograd.grad(\n",
    "        outputs=real_pred.sum(), inputs=real_img, create_graph=True\n",
    "    )\n",
    "    grad_penalty = grad_real.pow(2).reshape(grad_real.shape[0], -1).sum(1).mean()\n",
    "\n",
    "    return grad_penalty\n",
    "\n",
    "\n",
    "def g_nonsaturating_loss(fake_pred):\n",
    "    loss = F.softplus(-fake_pred).mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def g_path_regularize(fake_img, latents, mean_path_length, decay=0.01):\n",
    "    noise = torch.randn_like(fake_img) / math.sqrt(\n",
    "        fake_img.shape[2] * fake_img.shape[3]\n",
    "    )\n",
    "    grad, = autograd.grad(\n",
    "        outputs=(fake_img * noise).sum(), inputs=latents, create_graph=True\n",
    "    )\n",
    "    path_lengths = torch.sqrt(grad.pow(2).sum(2).mean(1))\n",
    "\n",
    "    path_mean = mean_path_length + decay * (path_lengths.mean() - mean_path_length)\n",
    "\n",
    "    path_penalty = (path_lengths - path_mean).pow(2).mean()\n",
    "\n",
    "    return path_penalty, path_mean.detach(), path_lengths\n",
    "\n",
    "\n",
    "def make_noise(batch, latent_dim, n_noise, device):\n",
    "    if n_noise == 1:\n",
    "        return torch.randn(batch, latent_dim, device=device)\n",
    "\n",
    "    noises = torch.randn(n_noise, batch, latent_dim, device=device).unbind(0)\n",
    "\n",
    "    return noises\n",
    "\n",
    "\n",
    "def mixing_noise(batch, latent_dim, prob, device):\n",
    "    if prob > 0 and random.random() < prob:\n",
    "        return make_noise(batch, latent_dim, 2, device)\n",
    "\n",
    "    else:\n",
    "        return [make_noise(batch, latent_dim, 1, device)]\n",
    "\n",
    "\n",
    "def set_grad_none(model, targets):\n",
    "    for n, p in model.named_parameters():\n",
    "        if n in targets:\n",
    "            p.grad = None\n",
    "\n",
    "\n",
    "def train(args, loader, generator, discriminator, g_optim, d_optim, g_ema, device):\n",
    "    loader = sample_data(loader)\n",
    "\n",
    "    pbar = range(args['iter'])\n",
    "\n",
    "    if get_rank() == 0:\n",
    "        pbar = tqdm(pbar, initial=args['start_iter'], dynamic_ncols=True, smoothing=0.01)\n",
    "\n",
    "    mean_path_length = 0\n",
    "\n",
    "    d_loss_val = 0\n",
    "    r1_loss = torch.tensor(0.0, device=device)\n",
    "    g_loss_val = 0\n",
    "    path_loss = torch.tensor(0.0, device=device)\n",
    "    path_lengths = torch.tensor(0.0, device=device)\n",
    "    mean_path_length_avg = 0\n",
    "    loss_dict = {}\n",
    "\n",
    "    if args['distributed']:\n",
    "        g_module = generator.module\n",
    "        d_module = discriminator.module\n",
    "\n",
    "    else:\n",
    "        g_module = generator\n",
    "        d_module = discriminator\n",
    "\n",
    "    accum = 0.5 ** (32 / (10 * 1000))\n",
    "    ada_augment = torch.tensor([0.0, 0.0], device=device)\n",
    "    ada_aug_p = args['augment_p'] if args['augment_p'] > 0 else 0.0\n",
    "    ada_aug_step = args['ada_target'] / args['ada_length']\n",
    "    r_t_stat = 0\n",
    "\n",
    "    sample_z = torch.randn(args['n_sample'], args['latent'], device=device)\n",
    "\n",
    "    for idx in pbar:\n",
    "        i = idx + args['start_iter']\n",
    "\n",
    "        if i > args['iter']:\n",
    "            print(\"Done!\")\n",
    "\n",
    "            break\n",
    "\n",
    "        real_img = next(loader)\n",
    "        real_img = real_img.to(device)\n",
    "\n",
    "        requires_grad(generator, False)\n",
    "        requires_grad(discriminator, True)\n",
    "\n",
    "        noise = mixing_noise(args['batch'], args['latent'], args['mixing'], device)\n",
    "        fake_img, _ = generator(noise)\n",
    "\n",
    "        if args.augment:\n",
    "            real_img_aug, _ = augment(real_img, ada_aug_p)\n",
    "            fake_img, _ = augment(fake_img, ada_aug_p)\n",
    "\n",
    "        else:\n",
    "            real_img_aug = real_img\n",
    "\n",
    "        fake_pred = discriminator(fake_img)\n",
    "        # print('fake images')\n",
    "        real_pred = discriminator(real_img_aug)\n",
    "        # print('real images')\n",
    "        d_loss = d_logistic_loss(real_pred, fake_pred)\n",
    "        # print('d loss')\n",
    "        loss_dict[\"d\"] = d_loss\n",
    "        loss_dict[\"real_score\"] = real_pred.mean()\n",
    "        loss_dict[\"fake_score\"] = fake_pred.mean()\n",
    "        discriminator.zero_grad()\n",
    "        print(d_loss)\n",
    "        d_loss.backward()\n",
    "        # print('backward')\n",
    "        d_optim.step()\n",
    "        print('d training complte')\n",
    "\n",
    "        if args['augment'] and args['augment_p'] == 0:\n",
    "            ada_augment_data = torch.tensor(\n",
    "                (torch.sign(real_pred).sum().item(), real_pred.shape[0]), device=device\n",
    "            )\n",
    "            ada_augment += reduce_sum(ada_augment_data)\n",
    "\n",
    "            if ada_augment[1] > 255:\n",
    "                pred_signs, n_pred = ada_augment.tolist()\n",
    "\n",
    "                r_t_stat = pred_signs / n_pred\n",
    "\n",
    "                if r_t_stat > args['ada_target']:\n",
    "                    sign = 1\n",
    "\n",
    "                else:\n",
    "                    sign = -1\n",
    "\n",
    "                ada_aug_p += sign * ada_aug_step * n_pred\n",
    "                ada_aug_p = min(1, max(0, ada_aug_p))\n",
    "                ada_augment.mul_(0)\n",
    "\n",
    "        d_regularize = i % args['d_reg_every'] == 0\n",
    "\n",
    "        if d_regularize:\n",
    "            real_img.requires_grad = True\n",
    "            real_pred = discriminator(real_img)\n",
    "            r1_loss = d_r1_loss(real_pred, real_img)\n",
    "\n",
    "            discriminator.zero_grad()\n",
    "            (args.r1 / 2 * r1_loss * args.d_reg_every + 0 * real_pred[0]).backward()\n",
    "\n",
    "            d_optim.step()\n",
    "\n",
    "        loss_dict[\"r1\"] = r1_loss\n",
    "\n",
    "        requires_grad(generator, True)\n",
    "        requires_grad(discriminator, False)\n",
    "\n",
    "        noise = mixing_noise(args['batch'], args['latent'], args['mixing'], device)\n",
    "        fake_img, _ = generator(noise)\n",
    "\n",
    "        if args.augment:\n",
    "            fake_img, _ = augment(fake_img, ada_aug_p)\n",
    "\n",
    "        fake_pred = discriminator(fake_img)\n",
    "        g_loss = g_nonsaturating_loss(fake_pred)\n",
    "\n",
    "        loss_dict[\"g\"] = g_loss\n",
    "\n",
    "        generator.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optim.step()\n",
    "\n",
    "        # print('g training complete')\n",
    "\n",
    "        g_regularize = i % args['g_reg_every'] == 0\n",
    "\n",
    "        if g_regularize:\n",
    "            path_batch_size = max(1, args['batch'] // args['path_batch_shrink'])\n",
    "            noise = mixing_noise(path_batch_size, args['latent'], args['latent'])\n",
    "            fake_img, latents = generator(noise, return_latents=True)\n",
    "\n",
    "            path_loss, mean_path_length, path_lengths = g_path_regularize(\n",
    "                fake_img, latents, mean_path_length\n",
    "            )\n",
    "\n",
    "            generator.zero_grad()\n",
    "            weighted_path_loss = args['path_regularize'] * args['g_reg_every'] * path_loss\n",
    "\n",
    "            if args['path_batch_shrink']:\n",
    "                weighted_path_loss += 0 * fake_img[0, 0, 0, 0]\n",
    "\n",
    "            weighted_path_loss.backward()\n",
    "\n",
    "            g_optim.step()\n",
    "\n",
    "            mean_path_length_avg = (\n",
    "                reduce_sum(mean_path_length).item() / get_world_size()\n",
    "            )\n",
    "\n",
    "        loss_dict[\"path\"] = path_loss\n",
    "        loss_dict[\"path_length\"] = path_lengths.mean()\n",
    "\n",
    "        accumulate(g_ema, g_module, accum)\n",
    "\n",
    "        loss_reduced = reduce_loss_dict(loss_dict)\n",
    "\n",
    "        d_loss_val = loss_reduced[\"d\"].mean().item()\n",
    "        g_loss_val = loss_reduced[\"g\"].mean().item()\n",
    "        r1_val = loss_reduced[\"r1\"].mean().item()\n",
    "        path_loss_val = loss_reduced[\"path\"].mean().item()\n",
    "        real_score_val = loss_reduced[\"real_score\"].mean().item()\n",
    "        fake_score_val = loss_reduced[\"fake_score\"].mean().item()\n",
    "        path_length_val = loss_reduced[\"path_length\"].mean().item()\n",
    "\n",
    "        if get_rank() == 0:\n",
    "            pbar.set_description(\n",
    "                (\n",
    "                    f\"d: {d_loss_val:.4f}; g: {g_loss_val:.4f}; r1: {r1_val:.4f}; \"\n",
    "                    f\"path: {path_loss_val:.4f}; mean path: {mean_path_length_avg:.4f}; \"\n",
    "                    f\"augment: {ada_aug_p:.4f}\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "#             if wandb and args.wandb:\n",
    "#                 wandb.log(\n",
    "#                     {\n",
    "#                         \"Generator\": g_loss_val,\n",
    "#                         \"Discriminator\": d_loss_val,\n",
    "#                         \"Augment\": ada_aug_p,\n",
    "#                         \"Rt\": r_t_stat,\n",
    "#                         \"R1\": r1_val,\n",
    "#                         \"Path Length Regularization\": path_loss_val,\n",
    "#                         \"Mean Path Length\": mean_path_length,\n",
    "#                         \"Real Score\": real_score_val,\n",
    "#                         \"Fake Score\": fake_score_val,\n",
    "#                         \"Path Length\": path_length_val,\n",
    "#                     }\n",
    "#                 )\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                with torch.no_grad():\n",
    "                    g_ema.eval()\n",
    "                    sample, _ = g_ema([sample_z])\n",
    "                    utils.save_image(\n",
    "                        sample,\n",
    "                        f\"sample/{str(i).zfill(6)}.png\",\n",
    "                        nrow=int(args['n_sample'] ** 0.5),\n",
    "                        normalize=True,\n",
    "                        range=(-1, 1),\n",
    "                    )\n",
    "\n",
    "            if i % 10000 == 0:\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"g\": g_module.state_dict(),\n",
    "                        \"d\": d_module.state_dict(),\n",
    "                        \"g_ema\": g_ema.state_dict(),\n",
    "                        \"g_optim\": g_optim.state_dict(),\n",
    "                        \"d_optim\": d_optim.state_dict(),\n",
    "                        \"args\": args,\n",
    "                        \"ada_aug_p\": ada_aug_p,\n",
    "                    },\n",
    "                    f\"checkpoint/{str(i).zfill(6)}.pt\",\n",
    "                )\n",
    "\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"path\", type=str)\n",
    "parser.add_argument(\"--iter\", type=int, default=800000)\n",
    "parser.add_argument(\"--batch\", type=int, default=16)\n",
    "parser.add_argument(\"--n_sample\", type=int, default=64)\n",
    "parser.add_argument(\"--size\", type=int, default=256)\n",
    "parser.add_argument(\"--r1\", type=float, default=10)\n",
    "parser.add_argument(\"--path_regularize\", type=float, default=2)\n",
    "parser.add_argument(\"--path_batch_shrink\", type=int, default=2)\n",
    "parser.add_argument(\"--d_reg_every\", type=int, default=16)\n",
    "parser.add_argument(\"--g_reg_every\", type=int, default=4)\n",
    "parser.add_argument(\"--mixing\", type=float, default=0.9)\n",
    "parser.add_argument(\"--ckpt\", type=str, default=None)\n",
    "parser.add_argument(\"--pretrained\", type=str, default=None)\n",
    "parser.add_argument(\"--start_iter\", type=int, default=0)\n",
    "parser.add_argument(\"--lr\", type=float, default=0.002)\n",
    "parser.add_argument(\"--channel_multiplier\", type=int, default=2)\n",
    "parser.add_argument(\"--wandb\", action=\"store_true\")\n",
    "parser.add_argument(\"--local_rank\", type=int, default=0)\n",
    "parser.add_argument(\"--augment\", action=\"store_true\")\n",
    "parser.add_argument(\"--augment_p\", type=float, default=0)\n",
    "parser.add_argument(\"--ada_target\", type=float, default=0.6)\n",
    "parser.add_argument(\"--ada_length\", type=int, default=500 * 1000)\n",
    "\n",
    "args = {'path': './images', 'iter':10000, 'batch':8, 'n_sample':8, 'size':256, 'r1':10, 'path_regularize':2, 'path_batch_shrink':2, 'd_reg_every':16,\n",
    "       'g_reg_every':4, 'mixing':0.9, 'ckpt':'', 'pretrained':'stylegan2-horse-config-f-pt', 'start_iter':0, 'lr':0.002, 'channel_multiplier':2, 'wandb':False, 'local_rank':0,\n",
    "       'augment':False, 'augment_p':0, 'ada_target':0.6, 'ada_length':500*1000}\n",
    "\n",
    "# n_gpu = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1\n",
    "n_gpu = 1\n",
    "args['distributed'] = n_gpu > 1\n",
    "\n",
    "if args['distributed']:\n",
    "    torch.cuda.set_device(args['local_rank'])\n",
    "    torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "    synchronize()\n",
    "\n",
    "args['latent'] = 512\n",
    "args['n_mlp'] = 8\n",
    "\n",
    "generator = Generator(\n",
    "    args['size'], args['latent'], args['n_mlp'], channel_multiplier=args['channel_multiplier']\n",
    ").to(device)\n",
    "discriminator = Discriminator(\n",
    "    args['size'], channel_multiplier=args['channel_multiplier']\n",
    ").to(device)\n",
    "g_ema = Generator(\n",
    "    args['size'], args['latent'], args['n_mlp'], channel_multiplier=args['hannel_multiplier']\n",
    ").to(device)\n",
    "g_ema.eval()\n",
    "accumulate(g_ema, generator, 0)\n",
    "\n",
    "g_reg_ratio = args['g_reg_every'] / (args['g_reg_every'] + 1)\n",
    "d_reg_ratio = args['d_reg_every'] / (args['d_reg_every'] + 1)\n",
    "\n",
    "g_optim = optim.Adam(\n",
    "    generator.parameters(),\n",
    "    lr=args['lr'] * g_reg_ratio,\n",
    "    betas=(0 ** g_reg_ratio, 0.99 ** g_reg_ratio),\n",
    ")\n",
    "d_optim = optim.Adam(\n",
    "    discriminator.parameters(),\n",
    "    lr=args['lr'] * d_reg_ratio,\n",
    "    betas=(0 ** d_reg_ratio, 0.99 ** d_reg_ratio),\n",
    ")\n",
    "\n",
    "if args['pretrained'] is not None:\n",
    "    print(\"load pretrained model: \", args['pretrained'])\n",
    "\n",
    "    pretrained = torch.load(args['pretrained'])\n",
    "\n",
    "    try:\n",
    "        pretrained_name = os.path.basename(args['pretrained'])\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    generator.load_state_dict(pretrained['g'])\n",
    "    discriminator.load_state_dict(pretrained['d'])\n",
    "    g_ema.load_state_dict(pretrained['g_ema'])\n",
    "\n",
    "# if args.ckpt is not None:\n",
    "#     print(\"load model:\", args.ckpt)\n",
    "\n",
    "#     ckpt = torch.load(args.ckpt, map_location=lambda storage, loc: storage)\n",
    "\n",
    "#     try:\n",
    "#         ckpt_name = os.path.basename(args.ckpt)\n",
    "#         args.start_iter = int(os.path.splitext(ckpt_name)[0])\n",
    "\n",
    "#     except ValueError:\n",
    "#         pass\n",
    "\n",
    "#     generator.load_state_dict(ckpt[\"g\"])\n",
    "#     discriminator.load_state_dict(ckpt[\"d\"])\n",
    "#     g_ema.load_state_dict(ckpt[\"g_ema\"])\n",
    "\n",
    "#     g_optim.load_state_dict(ckpt[\"g_optim\"])\n",
    "#     d_optim.load_state_dict(ckpt[\"d_optim\"])\n",
    "\n",
    "# if args.distributed:\n",
    "#     generator = nn.parallel.DistributedDataParallel(\n",
    "#         generator,\n",
    "#         device_ids=[args.local_rank],\n",
    "#         output_device=args.local_rank,\n",
    "#         broadcast_buffers=False,\n",
    "#     )\n",
    "\n",
    "#     discriminator = nn.parallel.DistributedDataParallel(\n",
    "#         discriminator,\n",
    "#         device_ids=[args.local_rank],\n",
    "#         output_device=args.local_rank,\n",
    "#         broadcast_buffers=False,\n",
    "#     )\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = MultiResolutionDataset(args['path'], transform, args['size'])\n",
    "\n",
    "loader = data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=args['batch'],\n",
    "    sampler=data_sampler(dataset, shuffle=True, distributed=args['distributed']),\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "# if get_rank() == 0 and wandb is not None and args.wandb:\n",
    "#     print('wandb')\n",
    "#     wandb.init(project=\"stylegan 2\")\n",
    "\n",
    "train(args, loader, generator, discriminator, g_optim, d_optim, g_ema, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-44f1052f660e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0m_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0m_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'a'"
     ]
    }
   ],
   "source": [
    "_a = {'a':5}\n",
    "_a.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
